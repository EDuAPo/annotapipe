# Pipeline æ¨¡å—

æ ‡æ³¨æ•°æ®å¤„ç†æµæ°´çº¿çš„æ ¸å¿ƒæ¨¡å—ï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œè´Ÿè´£ä» DataWeave å¹³å°ä¸‹è½½æ•°æ®ã€ä¸Šä¼ åˆ°è¿œç¨‹æœåŠ¡å™¨ã€å¤„ç†å’Œæ£€æŸ¥æ ‡æ³¨è´¨é‡ã€‚

> ğŸ‰ **æ¨¡å—çŠ¶æ€**: v1.0 å·²å®Œæˆï¼ŒåŠŸèƒ½ç¨³å®š

## ğŸ“ æ¨¡å—ç»“æ„

```
src/pipeline/
â”œâ”€â”€ __init__.py          # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”œâ”€â”€ ssh_client.py        # SSH/SFTP å®¢æˆ·ç«¯
â”œâ”€â”€ downloader.py        # æ–‡ä»¶ä¸‹è½½å™¨
â”œâ”€â”€ uploader.py          # æ–‡ä»¶ä¸Šä¼ å™¨
â”œâ”€â”€ processor.py         # è¿œç¨‹å¤„ç†å™¨
â”œâ”€â”€ checker.py           # æ ‡æ³¨æ£€æŸ¥å™¨
â”œâ”€â”€ tracker.py           # è¿›åº¦è¿½è¸ªå™¨
â”œâ”€â”€ server_logger.py     # æœåŠ¡å™¨æ—¥å¿—
â”œâ”€â”€ runner.py            # æµæ°´çº¿è¿è¡Œå™¨
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£

src/remote_scripts/      # è¿œç¨‹æ‰§è¡Œè„šæœ¬ï¼ˆå•ä¸€æ•°æ®æºï¼‰
â”œâ”€â”€ zip_worker.py        # ZIP è§£å‹å¤„ç†è„šæœ¬
â””â”€â”€ annotation_checker.py # æ ‡æ³¨è´¨é‡æ£€æŸ¥è„šæœ¬
```

## ğŸ”§ æ¨¡å—è¯´æ˜

### config.py - é…ç½®ç®¡ç†
```python
from pipeline.config import get_config, PipelineConfig

config = get_config()
server = config.get_available_server()
```

æ ¸å¿ƒç±»ï¼š
- `ServerConfig`: æœåŠ¡å™¨é…ç½®ï¼ˆhost, port, user, ç›®å½•è·¯å¾„ç­‰ï¼‰
- `DataWeaveConfig`: DataWeave API é…ç½®
- `PipelineConfig`: æµæ°´çº¿æ€»é…ç½®

### ssh_client.py - SSH å®¢æˆ·ç«¯
```python
from pipeline.ssh_client import SSHClient, create_ssh_client

with create_ssh_client() as ssh:
    status, out, err = ssh.exec_command("ls -la")
    ssh.upload_file("local.zip", "/remote/path.zip")
```

åŠŸèƒ½ï¼š
- SSH å‘½ä»¤æ‰§è¡Œ
- SFTP æ–‡ä»¶ä¸Šä¼ /ä¸‹è½½
- è¿œç¨‹æ–‡ä»¶/ç›®å½•æ“ä½œ
- è‡ªåŠ¨é‡è¿æœºåˆ¶

### downloader.py - æ–‡ä»¶ä¸‹è½½å™¨
```python
from pipeline.downloader import Downloader

downloader = Downloader()
success = downloader.download_file("filename.zip", target_path)
```

åŠŸèƒ½ï¼š
- DataWeave API Token ç®¡ç†ï¼ˆè‡ªåŠ¨åˆ·æ–°ï¼‰
- å¤šè·¯å¾„æ¨¡æ¿æŸ¥æ‰¾
- æ–­ç‚¹ç»­ä¼ æ”¯æŒ
- æ‰¹é‡ä¸‹è½½

### uploader.py - æ–‡ä»¶ä¸Šä¼ å™¨
```python
from pipeline.uploader import Uploader

uploader = Uploader(ssh)
success, msg = uploader.upload_file(local_path)
```

åŠŸèƒ½ï¼š
- SFTP æ‰¹é‡ä¸Šä¼ 
- è¿›åº¦å›è°ƒ
- é‡å¤æ–‡ä»¶æ£€æµ‹
- ä¸å®Œæ•´æ–‡ä»¶æ¸…ç†

### processor.py - è¿œç¨‹å¤„ç†å™¨
```python
from pipeline.processor import RemoteProcessor

processor = RemoteProcessor(ssh)
processor.deploy_scripts()  # éƒ¨ç½²è¿œç¨‹è„šæœ¬
success, err = processor.process_zip(zip_path, json_path, stem)
```

åŠŸèƒ½ï¼š
- è¿œç¨‹è„šæœ¬éƒ¨ç½²ï¼ˆä» `remote_scripts/` ç›®å½•åŠ¨æ€åŠ è½½ï¼‰
- ZIP è§£å‹å’Œç›®å½•ç»“æ„è°ƒæ•´
- æ ‡æ³¨è´¨é‡æ£€æŸ¥
- æ•°æ®ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•

### checker.py - æ ‡æ³¨æ£€æŸ¥å™¨
```python
from pipeline.checker import AnnotationChecker

checker = AnnotationChecker(ssh)
passed, issue_count, report = checker.check(data_dir, stem)
```

åŠŸèƒ½ï¼š
- æ ‡æ³¨è´¨é‡è§„åˆ™æ£€æŸ¥
- æ£€æŸ¥æŠ¥å‘Šç”Ÿæˆ
- å…³é”®å¸§æ•°é‡ç»Ÿè®¡
- æ‰¹é‡æ£€æŸ¥

### tracker.py - è¿›åº¦è¿½è¸ªå™¨
```python
from pipeline.tracker import Tracker, create_tracking_records

tracker = Tracker()
records = create_tracking_records(result, keyframe_counts)
tracker.track(records, json_dir)
```

åŠŸèƒ½ï¼š
- æœ¬åœ°æŠ¥å‘Šç”Ÿæˆ
- é£ä¹¦è¡¨æ ¼åŒæ­¥ï¼ˆå¯é€‰ï¼‰
- å±æ€§è‡ªåŠ¨æ£€æµ‹

### server_logger.py - æœåŠ¡å™¨æ—¥å¿—
```python
from pipeline.server_logger import ServerLogger

logger = ServerLogger(ssh)
logger.log_success(data_name, keyframe_count)
logger.print_summary()
```

åŠŸèƒ½ï¼š
- å¤„ç†è®°å½•æŒä¹…åŒ–
- æ—¥å¿—æŸ¥è¯¢å’Œç»Ÿè®¡
- æ—¥å¿—è½®è½¬

### runner.py - æµæ°´çº¿è¿è¡Œå™¨
```python
from pipeline.runner import PipelineRunner

runner = PipelineRunner(json_dir="/path/to/jsons")
runner.run(mode="optimized", workers=3)
```

è¿è¡Œæ¨¡å¼ï¼š
- `optimized`: ä¼˜åŒ–æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼Œæ™ºèƒ½è°ƒåº¦
- `streaming`: æµå¼æ¨¡å¼ï¼Œé€ä¸ªå¤„ç†
- `parallel`: å¹¶è¡Œæ¨¡å¼ï¼Œå¤šçº¿ç¨‹å¤„ç†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨
```python
from pipeline import PipelineRunner

# åˆ›å»ºè¿è¡Œå™¨
runner = PipelineRunner(
    json_dir="data/",           # JSON æ–‡ä»¶ç›®å½•
    local_zip_dir="/tmp/zips"   # æœ¬åœ° ZIP ç¼“å­˜ç›®å½•
)

# è¿è¡Œæµæ°´çº¿
runner.run(mode="optimized", workers=3)
```

### å‘½ä»¤è¡Œä½¿ç”¨
```bash
python run_pipeline.py --json_dir data/ --mode parallel --workers 4
```

## ğŸ“ æ¶æ„è®¾è®¡

### å•ä¸€æ•°æ®æºåŸåˆ™

è¿œç¨‹è„šæœ¬é‡‡ç”¨å•ä¸€æ•°æ®æºè®¾è®¡ï¼š

```
src/remote_scripts/           # å”¯ä¸€çš„è„šæœ¬æº
â”œâ”€â”€ zip_worker.py            # ZIP å¤„ç†è„šæœ¬
â””â”€â”€ annotation_checker.py    # æ£€æŸ¥è„šæœ¬

src/pipeline/processor.py    # åŠ¨æ€åŠ è½½è„šæœ¬
â””â”€â”€ _load_script(name)       # ä» remote_scripts/ è¯»å–
```

`processor.py` é€šè¿‡ `_load_script()` å‡½æ•°åŠ¨æ€è¯»å–è„šæœ¬å†…å®¹ï¼š

```python
LOCAL_SCRIPTS_DIR = Path(__file__).parent.parent / "remote_scripts"

def _load_script(name: str) -> str:
    """ä» remote_scripts ç›®å½•åŠ è½½è„šæœ¬å†…å®¹"""
    script_path = LOCAL_SCRIPTS_DIR / name
    return script_path.read_text(encoding='utf-8')
```

å¥½å¤„ï¼š
- æ¶ˆé™¤ä»£ç é‡å¤
- è„šæœ¬å¯ç‹¬ç«‹æµ‹è¯•
- ç»´æŠ¤æ›´ç®€å•

### æ¨¡å—ä¾èµ–å…³ç³»

```
runner.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ ssh_client.py
    â”œâ”€â”€ downloader.py
    â”œâ”€â”€ uploader.py
    â”œâ”€â”€ processor.py
    â”‚   â””â”€â”€ remote_scripts/*.py (åŠ¨æ€åŠ è½½)
    â”œâ”€â”€ checker.py
    â”œâ”€â”€ tracker.py
    â””â”€â”€ server_logger.py
```

### å¤„ç†æµç¨‹

```
1. ä¸‹è½½ ZIP (downloader)
       â†“
2. ä¸Šä¼ åˆ°æœåŠ¡å™¨ (uploader)
       â†“
3. è§£å‹å¹¶å¤„ç† (processor)
       â†“
4. è´¨é‡æ£€æŸ¥ (checker)
       â†“
5. ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½• (processor)
       â†“
6. è®°å½•å’Œè¿½è¸ª (tracker, server_logger)
```

## âš™ï¸ é…ç½®æ–‡ä»¶

### configs/pipeline.yaml
```yaml
# æœåŠ¡å™¨é…ç½®
servers:
  - host: "192.168.1.100"
    port: 22
    user: "admin"
    password: "xxx"
    zip_dir: "/data02/rere_zips"
    process_dir: "/data02/processing"
    final_dir: "/data02/"

# DataWeave é…ç½®
dataweave:
  base_url: "https://api.dataweave.com"
  username: "user"
  password: "pass"

# æµæ°´çº¿é…ç½®
pipeline:
  rename_json: true
  zip_after_process: "rename"  # rename/delete/keep
  check_config_path: "configs/check_rules.yaml"
```

## ğŸ” é”™è¯¯å¤„ç†

æ¯ä¸ªæ¨¡å—éƒ½æœ‰å®Œå–„çš„é”™è¯¯å¤„ç†ï¼š

```python
try:
    success, err = processor.process_zip(zip_path, json_path, stem)
    if not success:
        logger.log_failure(stem, err)
except Exception as e:
    logger.error(f"å¤„ç†å¤±è´¥: {e}")
```

## ğŸ“Š æ—¥å¿—è¾“å‡º

```
[10:30:15] âœ… ä¸‹è½½å®Œæˆ: 1209_134548_134748.zip
[10:30:20] âœ… ä¸Šä¼ å®Œæˆ: 1209_134548_134748.zip
[10:30:45] âœ… å¤„ç†å®Œæˆ: 1209_134548_134748
[10:30:50] âœ… æ£€æŸ¥é€šè¿‡: 1209_134548_134748 (200 å¸§)
[10:30:51] âœ… ç§»åŠ¨å®Œæˆ: /data02/1209_134548_134748

å¤„ç†å®Œæˆ! æˆåŠŸ: 95/100, å¤±è´¥: 5
```

## ğŸ§ª æµ‹è¯•

```bash
# æµ‹è¯•å•ä¸ªæ¨¡å—
python -c "from pipeline.ssh_client import SSHClient; print('OK')"

# æµ‹è¯•è¿œç¨‹è„šæœ¬åŠ è½½
python -c "from pipeline.processor import _load_script; print(_load_script('zip_worker.py')[:100])"
```

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„è¿œç¨‹è„šæœ¬

1. åœ¨ `src/remote_scripts/` åˆ›å»ºè„šæœ¬æ–‡ä»¶
2. åœ¨ `processor.py` ä¸­ä½¿ç”¨ `_load_script()` åŠ è½½
3. æ·»åŠ éƒ¨ç½²å’Œæ‰§è¡Œé€»è¾‘

### æ·»åŠ æ–°çš„å¤„ç†æ­¥éª¤

1. åˆ›å»ºæ–°æ¨¡å—ï¼ˆå¦‚ `validator.py`ï¼‰
2. åœ¨ `runner.py` ä¸­é›†æˆ
3. æ›´æ–°é…ç½®å’Œæ–‡æ¡£
