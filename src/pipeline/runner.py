"""
æµæ°´çº¿è¿è¡Œå™¨
è´Ÿè´£ç¼–æ’æ•´ä¸ªå¤„ç†æµç¨‹ï¼Œæ”¯æŒä¸²è¡Œ/å¹¶è¡Œæ¨¡å¼
"""
import sys
import logging
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue

from .config import get_config, PipelineConfig
from .ssh_client import SSHClient
from .downloader import Downloader
from .processor import RemoteProcessor
from .server_logger import ServerLogger
from .tracker import Tracker, create_tracking_records

logger = logging.getLogger(__name__)


@dataclass
class PipelineResult:
    """æµæ°´çº¿æ‰§è¡Œç»“æœ"""
    downloaded: List[str] = field(default_factory=list)
    download_failed: List[str] = field(default_factory=list)
    skipped_server_exists: List[str] = field(default_factory=list)
    uploaded: List[str] = field(default_factory=list)
    processed: List[str] = field(default_factory=list)
    check_passed: List[str] = field(default_factory=list)
    check_failed: List[str] = field(default_factory=list)
    moved_to_final: List[str] = field(default_factory=list)
    keyframe_counts: Dict[str, int] = field(default_factory=dict)
    errors: Dict[str, List[tuple]] = field(default_factory=dict)
    
    def log_error(self, stem: str, step: str, msg: str):
        if stem not in self.errors:
            self.errors[stem] = []
        self.errors[stem].append((step, msg))


class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨"""
    
    def __init__(self, total: int, title: str = "å¤„ç†è¿›åº¦"):
        self.total = total
        self.completed = 0
        self.success = 0
        self.failed = 0
        self.title = title
        self.lock = threading.Lock()
        self.start_time = datetime.now()
    
    def update(self, success: bool = True, name: str = ""):
        with self.lock:
            self.completed += 1
            if success:
                self.success += 1
            else:
                self.failed += 1
            self._display(name, success)
    
    def _display(self, name: str, success: bool):
        percent = self.completed / self.total * 100 if self.total > 0 else 0
        width = 25
        filled = int(width * self.completed / self.total) if self.total > 0 else 0
        bar = 'â”' * filled + 'â•¸' + 'â”€' * (width - filled - 1) if filled < width else 'â”' * width
        status = "âœ“" if success else "âœ—"
        
        sys.stdout.write(f'\r\033[K')
        sys.stdout.write(f'[{bar}] {self.completed}/{self.total} ({percent:.0f}%) â”‚ {status} {name[:30]:<30}')
        sys.stdout.flush()
        
        if self.completed >= self.total:
            print()
    
    def summary(self):
        elapsed = (datetime.now() - self.start_time).seconds
        mins, secs = divmod(elapsed, 60)
        print(f"\n{'â”€'*50}")
        print(f"  ğŸ“Š {self.title} å®Œæˆ")
        print(f"  âœ“ æˆåŠŸ: {self.success}  âœ— å¤±è´¥: {self.failed}  â± è€—æ—¶: {mins}åˆ†{secs}ç§’")
        print(f"{'â”€'*50}")


class SSHConnectionPool:
    """SSH è¿æ¥æ± ï¼Œç”¨äºå¹¶è¡Œæ¨¡å¼å¤ç”¨è¿æ¥"""
    
    def __init__(self, size: int = 3):
        self._pool: Queue = Queue()
        self._size = size
        self._created = 0
        self._lock = threading.Lock()
        self._scripts_deployed = False
    
    def get(self) -> Optional[SSHClient]:
        """è·å–ä¸€ä¸ªè¿æ¥"""
        # å…ˆå°è¯•ä»æ± ä¸­è·å–
        if not self._pool.empty():
            try:
                return self._pool.get_nowait()
            except:
                pass
        
        # åˆ›å»ºæ–°è¿æ¥
        with self._lock:
            if self._created < self._size:
                ssh = SSHClient()
                if ssh.connect():
                    self._created += 1
                    return ssh
        
        # ç­‰å¾…å¯ç”¨è¿æ¥
        return self._pool.get(timeout=60)
    
    def put(self, ssh: SSHClient):
        """å½’è¿˜è¿æ¥"""
        if ssh and ssh.is_connected:
            self._pool.put(ssh)
    
    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        while not self._pool.empty():
            try:
                ssh = self._pool.get_nowait()
                ssh.close()
            except:
                pass


class PipelineRunner:
    """æµæ°´çº¿è¿è¡Œå™¨"""
    
    def __init__(self, json_dir: str, local_zip_dir: str = None, config: PipelineConfig = None):
        self.config = config or get_config()
        self.json_dir = Path(json_dir)
        
        # æœ¬åœ°ç›®å½•
        base_dir = Path(local_zip_dir) if local_zip_dir else Path(self.config.local_temp_dir)
        self.local_zip_dir = base_dir / "zips"
        self.local_check_dir = base_dir / "check_data"
        self.local_zip_dir.mkdir(parents=True, exist_ok=True)
        self.local_check_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»„ä»¶
        self.downloader = Downloader(self.config.dataweave)
        self.result = PipelineResult()
        self._lock = threading.Lock()
        self._deploy_lock = threading.Lock()
        self._scripts_deployed = False
        self.server_logger: Optional[ServerLogger] = None
    
    def run(self, mode: str = "optimized", workers: int = None):
        """
        è¿è¡Œæµæ°´çº¿
        mode: optimized (ä¸‹è½½å¹¶è¡Œ+æœåŠ¡å™¨ä¸²è¡Œ), parallel (å…¨å¹¶è¡Œ), streaming (æµå¼)
        """
        workers = workers or self.config.max_workers
        
        print()
        print("â•”" + "â•" * 50 + "â•—")
        print(f"â•‘  ğŸ“¦ æ ‡æ³¨æ•°æ®å¤„ç†æµæ°´çº¿ ({mode}æ¨¡å¼)".ljust(51) + "â•‘")
        print("â•š" + "â•" * 50 + "â•")
        print(f"  ğŸ“ JSONç›®å½•: {self.json_dir}")
        
        json_files = list(self.json_dir.glob("*.json"))
        if not json_files:
            print("  âš  æœªæ‰¾åˆ° JSON æ–‡ä»¶")
            return self.result
        
        print(f"  ğŸ“‹ å…± {len(json_files)} ä¸ªæ–‡ä»¶")
        
        with SSHClient() as ssh:
            if not ssh.is_connected:
                print("  âœ— æ— æ³•è¿æ¥æœåŠ¡å™¨")
                return self.result
            
            print(f"  ğŸ”— å·²è¿æ¥æœåŠ¡å™¨: {ssh.server.ip}")
            
            processor = RemoteProcessor(ssh, self.config)
            processor.deploy_scripts()
            
            # åˆå§‹åŒ–æœåŠ¡å™¨æ—¥å¿—
            self.server_logger = ServerLogger(ssh)
            print(f"  ğŸ“‹ æœåŠ¡å™¨æ—¥å¿—: {self.server_logger.log_file}")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            ssh.mkdir_p(ssh.server.zip_dir)
            ssh.mkdir_p(ssh.server.process_dir)
            
            # æ¸…ç†æ®‹ç•™çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆä¸Šæ¬¡å¼‚å¸¸ä¸­æ–­å¯èƒ½ç•™ä¸‹çš„ï¼‰
            cleaned = ssh.cleanup_uploading_files(ssh.server.zip_dir)
            if cleaned > 0:
                print(f"  ğŸ§¹ æ¸…ç†æ®‹ç•™ä¸´æ—¶æ–‡ä»¶: {cleaned} ä¸ª")
            
            # è·å–æœåŠ¡å™¨çŠ¶æ€
            state = processor.get_server_state()
            print(f"  ğŸ“Š æœåŠ¡å™¨çŠ¶æ€: {len(state['zip_files'])} ZIPs / {len(state['processed_dirs'])} å·²å®Œæˆ")
            
            # è¿‡æ»¤éœ€è¦å¤„ç†çš„æ–‡ä»¶
            files_to_process = []
            for json_file in json_files:
                stem = json_file.stem
                if stem in state['processed_dirs']:
                    # æœåŠ¡å™¨ä¸Šå·²å®Œæˆçš„æ–‡ä»¶ï¼Œè®°å½•ä¸ºè·³è¿‡
                    self.result.skipped_server_exists.append(stem)
                    self.result.check_passed.append(stem)
                    # è·å–å…³é”®å¸§æ•°é‡
                    kf = processor.get_keyframe_count(f"{ssh.server.final_dir}/{stem}")
                    self.result.keyframe_counts[stem] = kf
                else:
                    files_to_process.append((json_file, stem))
            
            skipped = len(json_files) - len(files_to_process)
            if skipped > 0:
                print(f"  â­ è·³è¿‡å·²å®Œæˆ: {skipped} ä¸ª")
            
            if not files_to_process:
                print("  âœ“ æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆ")
                self._print_summary()
                # é£ä¹¦è¿½è¸ªï¼šå³ä½¿å…¨éƒ¨è·³è¿‡ä¹Ÿè¦åŒæ­¥
                self._track_to_feishu()
                return self.result
            
            print(f"  ğŸ“¦ å¾…å¤„ç†: {len(files_to_process)} ä¸ªæ–‡ä»¶")
            print(f"  ğŸ§µ å¹¶å‘æ•°: {workers}")
            print()
            
            if mode == "optimized":
                self._run_optimized(ssh, processor, files_to_process, state, workers)
            elif mode == "parallel":
                self._run_parallel(processor, files_to_process, state, workers)
            else:
                self._run_streaming(ssh, processor, files_to_process, state)
        
        self._print_summary()
        
        # é£ä¹¦è¿½è¸ªï¼šè®°å½•æ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼ˆåŒ…æ‹¬è·³è¿‡çš„ï¼‰
        self._track_to_feishu()
        
        return self.result
    
    def _run_optimized(self, ssh: SSHClient, processor: RemoteProcessor,
                       files: List[tuple], state: Dict, workers: int):
        """ä¼˜åŒ–æ¨¡å¼ï¼šä¸‹è½½å¹¶è¡Œ + æœåŠ¡å™¨æ“ä½œä¸²è¡Œ"""
        
        # é˜¶æ®µ1: å¹¶è¡Œä¸‹è½½
        print("=" * 50)
        print("  ğŸ“¥ é˜¶æ®µ1: å¹¶è¡Œä¸‹è½½ ZIP æ–‡ä»¶")
        print("=" * 50)
        
        files_to_download = []
        for json_file, stem in files:
            zip_name = f"{stem}.zip"
            local_zip = self.local_zip_dir / zip_name
            
            if zip_name in state['zip_files']:
                self.result.skipped_server_exists.append(stem)
                continue
            if self.downloader.is_valid_zip(local_zip):
                self.result.downloaded.append(stem)
                continue
            files_to_download.append((stem, zip_name, local_zip))
        
        if files_to_download:
            print(f"  éœ€ä¸‹è½½: {len(files_to_download)} ä¸ªæ–‡ä»¶")
            progress = ProgressTracker(len(files_to_download), "ä¸‹è½½è¿›åº¦")
            
            with ThreadPoolExecutor(max_workers=self.config.download_workers) as executor:
                futures = {}
                for stem, zip_name, local_zip in files_to_download:
                    future = executor.submit(self.downloader.download_file, zip_name, local_zip)
                    futures[future] = stem
                
                for future in as_completed(futures):
                    stem = futures[future]
                    try:
                        success = future.result()
                        with self._lock:
                            if success:
                                self.result.downloaded.append(stem)
                            else:
                                self.result.download_failed.append(stem)
                        progress.update(success=success, name=stem)
                    except Exception:
                        with self._lock:
                            self.result.download_failed.append(stem)
                        progress.update(success=False, name=f"{stem} (å¼‚å¸¸)")
            
            progress.summary()
        else:
            print("  æ‰€æœ‰æ–‡ä»¶å·²ä¸‹è½½æˆ–æœåŠ¡å™¨å·²å­˜åœ¨")
        
        # é˜¶æ®µ2: ä¸²è¡ŒæœåŠ¡å™¨æ“ä½œ
        print()
        print("=" * 50)
        print("  ğŸ”„ é˜¶æ®µ2: ä¸²è¡ŒæœåŠ¡å™¨æ“ä½œ")
        print("=" * 50)
        
        files_for_server = [(jf, stem) for jf, stem in files if stem not in self.result.download_failed]
        
        if not files_for_server:
            print("  æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
            return
        
        progress = ProgressTracker(len(files_for_server), "æœåŠ¡å™¨å¤„ç†")
        
        for json_file, stem in files_for_server:
            success = self._process_single(ssh, processor, json_file, stem, state)
            progress.update(success=success, name=stem)
        
        progress.summary()
    
    def _run_parallel(self, processor: RemoteProcessor, files: List[tuple], 
                      state: Dict, workers: int):
        """å…¨å¹¶è¡Œæ¨¡å¼ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨ SSH è¿æ¥"""
        progress = ProgressTracker(len(files), "å¹¶è¡Œå¤„ç†")
        pool = SSHConnectionPool(size=workers)
        
        try:
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = {}
                for json_file, stem in files:
                    future = executor.submit(
                        self._process_with_pool, 
                        pool, json_file, stem, state
                    )
                    futures[future] = stem
                
                for future in as_completed(futures):
                    stem = futures[future]
                    try:
                        success = future.result()
                        progress.update(success=success, name=stem)
                    except Exception as e:
                        logger.error(f"å¹¶è¡Œå¤„ç†å¼‚å¸¸ {stem}: {e}")
                        progress.update(success=False, name=f"{stem} (å¼‚å¸¸)")
        finally:
            pool.close_all()
        
        progress.summary()
    
    def _run_streaming(self, ssh: SSHClient, processor: RemoteProcessor,
                       files: List[tuple], state: Dict):
        """æµå¼æ¨¡å¼ï¼šä¸‹è½½ä¸€ä¸ªå¤„ç†ä¸€ä¸ª"""
        progress = ProgressTracker(len(files), "æµå¼å¤„ç†")
        
        for json_file, stem in files:
            success = self._process_single(ssh, processor, json_file, stem, state)
            progress.update(success=success, name=stem)
        
        progress.summary()
    
    def _process_single(self, ssh: SSHClient, processor: RemoteProcessor,
                        json_file: Path, stem: str, state: Dict) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆä½¿ç”¨å…±äº«SSHè¿æ¥ï¼‰"""
        zip_name = f"{stem}.zip"
        local_zip = self.local_zip_dir / zip_name
        server = ssh.server
        remote_zip = f"{server.zip_dir}/{zip_name}"
        
        try:
            # ä¸‹è½½
            if zip_name not in state['zip_files'] and not self.downloader.is_valid_zip(local_zip):
                if not self.downloader.download_file(zip_name, local_zip):
                    self.result.log_error(stem, "ä¸‹è½½", "ä¸‹è½½å¤±è´¥")
                    self.result.check_failed.append(stem)
                    return False
                self.result.downloaded.append(stem)
            
            # ä¸Šä¼ 
            if zip_name not in state['zip_files'] and local_zip.exists():
                if not ssh.upload_file(str(local_zip), remote_zip):
                    self.result.log_error(stem, "ä¸Šä¼ ", "ä¸Šä¼ å¤±è´¥")
                    self.result.check_failed.append(stem)
                    return False
                self.result.uploaded.append(stem)
            
            # å¤„ç†
            success, err = processor.process_zip(remote_zip, str(json_file), stem)
            if not success:
                self.result.log_error(stem, "å¤„ç†", err)
                self.result.check_failed.append(stem)
                return False
            self.result.processed.append(stem)
            
            # æ£€æŸ¥
            data_dir = f"{server.process_dir}/{stem}"
            passed, issue_count, report = processor.check_annotations(data_dir, stem)
            
            # è·å–å…³é”®å¸§æ•°é‡
            kf = processor.get_keyframe_count(data_dir)
            self.result.keyframe_counts[stem] = kf
            
            if not passed:
                self.result.log_error(stem, "æ£€æŸ¥", f"å‘ç° {issue_count} ä¸ªé—®é¢˜å¸§")
                self.result.check_failed.append(stem)
                # ä¸‹è½½æŠ¥å‘Š
                local_report = self.local_check_dir / f"report_{stem}.txt"
                ssh.download_file(report, str(local_report))
                return False
            
            self.result.check_passed.append(stem)
            
            # ç§»åŠ¨
            success, dst = processor.move_to_final(stem)
            if success:
                self.result.moved_to_final.append(stem)
                # æ¸…ç†æœ¬åœ°ZIP
                if local_zip.exists():
                    local_zip.unlink()
                # è®°å½•æœåŠ¡å™¨æ—¥å¿—
                if self.server_logger:
                    self.server_logger.log_success(stem, kf)
            else:
                self.result.log_error(stem, "ç§»åŠ¨", dst)
            
            return True
            
        except Exception as e:
            self.result.log_error(stem, "å¼‚å¸¸", str(e))
            self.result.check_failed.append(stem)
            # è®°å½•å¤±è´¥æ—¥å¿—
            if self.server_logger:
                self.server_logger.log_failure(stem, str(e))
            return False
    
    def _process_with_pool(self, pool: SSHConnectionPool, json_file: Path, 
                           stem: str, state: Dict) -> bool:
        """ä½¿ç”¨è¿æ¥æ± å¤„ç†å•ä¸ªæ–‡ä»¶"""
        ssh = None
        try:
            ssh = pool.get()
            if not ssh or not ssh.is_connected:
                self.result.log_error(stem, "è¿æ¥", "æ— æ³•è·å–SSHè¿æ¥")
                with self._lock:
                    self.result.check_failed.append(stem)
                return False
            
            processor = RemoteProcessor(ssh, self.config)
            
            # çº¿ç¨‹å®‰å…¨çš„è„šæœ¬éƒ¨ç½²ï¼ˆåªéƒ¨ç½²ä¸€æ¬¡ï¼‰
            with self._deploy_lock:
                if not self._scripts_deployed:
                    processor.deploy_scripts()
                    self._scripts_deployed = True
            
            return self._process_single(ssh, processor, json_file, stem, state)
        finally:
            if ssh:
                pool.put(ssh)
    
    def _process_single_threaded(self, json_file: Path, stem: str, state: Dict) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆç‹¬ç«‹SSHè¿æ¥ï¼Œç”¨äºå¹¶è¡Œæ¨¡å¼ï¼‰- å·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹"""
        with SSHClient() as ssh:
            if not ssh.is_connected:
                self.result.log_error(stem, "è¿æ¥", "SSHè¿æ¥å¤±è´¥")
                with self._lock:
                    self.result.check_failed.append(stem)
                return False
            
            processor = RemoteProcessor(ssh, self.config)
            processor.deploy_scripts()
            return self._process_single(ssh, processor, json_file, stem, state)
    
    def _print_summary(self):
        """æ‰“å°æ‰§è¡Œæ±‡æ€»"""
        print()
        print("â•”" + "â•" * 50 + "â•—")
        print("â•‘  ğŸ“Š æ‰§è¡Œæ±‡æ€»".ljust(51) + "â•‘")
        print("â• " + "â•" * 50 + "â•£")
        
        stats = [
            ("â­ è·³è¿‡(å·²å­˜åœ¨)", len(self.result.skipped_server_exists)),
            ("â¬‡ ä¸‹è½½æˆåŠŸ", len(self.result.downloaded)),
            ("â¬‡ ä¸‹è½½å¤±è´¥", len(self.result.download_failed)),
            ("â¬† ä¸Šä¼ æˆåŠŸ", len(self.result.uploaded)),
            ("âš™ å¤„ç†æˆåŠŸ", len(self.result.processed)),
            ("âœ“ æ£€æŸ¥é€šè¿‡", len(self.result.check_passed)),
            ("âœ— æ£€æŸ¥å¤±è´¥", len(self.result.check_failed)),
            ("ğŸ“ å·²ç§»åŠ¨", len(self.result.moved_to_final)),
        ]
        
        total_kf = sum(self.result.keyframe_counts.values())
        if total_kf > 0:
            stats.append(("ğŸ“Š æ€»å…³é”®å¸§", total_kf))
        
        for label, count in stats:
            line = f"â•‘  {label}: {count}"
            print(line.ljust(51) + "â•‘")
        
        print("â•š" + "â•" * 50 + "â•")
        
        if self.result.check_failed:
            print()
            print("  âš  æ£€æŸ¥æœªé€šè¿‡çš„æ•°æ®:")
            for name in self.result.check_failed:
                print(f"    â€¢ {name}")
        
        if self.result.errors:
            print()
            print("  âŒ å¤±è´¥è¯¦æƒ…:")
            for stem, error_list in self.result.errors.items():
                print(f"    â”Œâ”€ {stem}")
                for step, msg in error_list:
                    display_msg = msg[:60] + "..." if len(msg) > 60 else msg
                    print(f"    â”‚  [{step}] {display_msg}")
                print(f"    â””â”€")
    
    def _track_to_feishu(self):
        """å°†å¤„ç†ç»“æœåŒæ­¥åˆ°é£ä¹¦è¡¨æ ¼ï¼ˆåŒ…æ‹¬è·³è¿‡çš„æ–‡ä»¶ï¼‰"""
        try:
            tracker = Tracker()
            records = create_tracking_records(self.result, self.result.keyframe_counts)
            
            if not records:
                logger.info("æ²¡æœ‰éœ€è¦è¿½è¸ªçš„è®°å½•")
                return
            
            print()
            print(f"  ğŸ“¤ åŒæ­¥åˆ°é£ä¹¦: {len(records)} æ¡è®°å½•...")
            
            result = tracker.track(records, str(self.json_dir))
            
            if result:
                created = result.get('created', 0)
                updated = result.get('updated', 0)
                if isinstance(created, list):
                    created = len(created)
                if isinstance(updated, list):
                    updated = len(updated)
                print(f"  âœ… é£ä¹¦åŒæ­¥å®Œæˆ: æ–°å¢ {created}, æ›´æ–° {updated}")
        except Exception as e:
            logger.warning(f"é£ä¹¦è¿½è¸ªå¤±è´¥: {e}")
            print(f"  âš  é£ä¹¦åŒæ­¥å¤±è´¥: {e}")
