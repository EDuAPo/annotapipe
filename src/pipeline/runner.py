"""
æµæ°´çº¿è¿è¡Œå™¨
è´Ÿè´£ç¼–æ’æ•´ä¸ªå¤„ç†æµç¨‹ï¼Œæ”¯æŒä¸²è¡Œ/å¹¶è¡Œæ¨¡å¼
"""
import sys
import time
import logging
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue

from .config import get_config, PipelineConfig
from .ssh_client import SSHClient
from .downloader import Downloader
from .processor import RemoteProcessor
from .server_logger import ServerLogger
from .tracker import Tracker, TrackingRecord
from .state import StateManager, ProcessStatus

logger = logging.getLogger(__name__)


@dataclass
class PipelineResult:
    """æµæ°´çº¿æ‰§è¡Œç»“æœ"""
    downloaded: List[str] = field(default_factory=list)
    download_failed: List[str] = field(default_factory=list)
    skipped_server_exists: List[str] = field(default_factory=list)
    uploaded: List[str] = field(default_factory=list)
    processed: List[str] = field(default_factory=list)
    check_passed: List[str] = field(default_factory=list)
    check_failed: List[str] = field(default_factory=list)
    moved_to_final: List[str] = field(default_factory=list)
    keyframe_counts: Dict[str, int] = field(default_factory=dict)
    errors: Dict[str, List[tuple]] = field(default_factory=dict)
    
    def log_error(self, stem: str, step: str, msg: str):
        if stem not in self.errors:
            self.errors[stem] = []
        self.errors[stem].append((step, msg))


class ProgressTracker:
    """è¿›åº¦è¿½è¸ªå™¨"""
    
    def __init__(self, total: int, title: str = "å¤„ç†è¿›åº¦"):
        self.total = total
        self.completed = 0
        self.success = 0
        self.failed = 0
        self.title = title
        self.lock = threading.Lock()
        self.start_time = datetime.now()
    
    def update(self, success: bool = True, name: str = ""):
        with self.lock:
            self.completed += 1
            if success:
                self.success += 1
            else:
                self.failed += 1
            self._display(name, success)
    
    def _display(self, name: str, success: bool):
        percent = self.completed / self.total * 100 if self.total > 0 else 0
        width = 25
        filled = int(width * self.completed / self.total) if self.total > 0 else 0
        bar = 'â”' * filled + 'â•¸' + 'â”€' * (width - filled - 1) if filled < width else 'â”' * width
        status = "âœ“" if success else "âœ—"
        
        sys.stdout.write(f'\r\033[K')
        sys.stdout.write(f'[{bar}] {self.completed}/{self.total} ({percent:.0f}%) â”‚ {status} {name[:30]:<30}')
        sys.stdout.flush()
        
        if self.completed >= self.total:
            print()
    
    def summary(self):
        elapsed = (datetime.now() - self.start_time).seconds
        mins, secs = divmod(elapsed, 60)
        print(f"\n{'â”€'*50}")
        print(f"  ğŸ“Š {self.title} å®Œæˆ")
        print(f"  âœ“ æˆåŠŸ: {self.success}  âœ— å¤±è´¥: {self.failed}  â± è€—æ—¶: {mins}åˆ†{secs}ç§’")
        print(f"{'â”€'*50}")


class SSHConnectionPool:
    """SSH è¿æ¥æ± ï¼Œç”¨äºå¹¶è¡Œæ¨¡å¼å¤ç”¨è¿æ¥"""
    
    def __init__(self, size: int = 3):
        self._pool: Queue = Queue()
        self._size = size
        self._created = 0
        self._lock = threading.Lock()
        self._scripts_deployed = False
    
    def get(self) -> Optional[SSHClient]:
        """è·å–ä¸€ä¸ªè¿æ¥"""
        # å…ˆå°è¯•ä»æ± ä¸­è·å–
        if not self._pool.empty():
            try:
                return self._pool.get_nowait()
            except:
                pass
        
        # åˆ›å»ºæ–°è¿æ¥
        with self._lock:
            if self._created < self._size:
                ssh = SSHClient()
                if ssh.connect():
                    self._created += 1
                    return ssh
        
        # ç­‰å¾…å¯ç”¨è¿æ¥
        return self._pool.get(timeout=60)
    
    def put(self, ssh: SSHClient):
        """å½’è¿˜è¿æ¥"""
        if ssh and ssh.is_connected:
            self._pool.put(ssh)
    
    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        while not self._pool.empty():
            try:
                ssh = self._pool.get_nowait()
                ssh.close()
            except:
                pass


class PipelineRunner:
    """æµæ°´çº¿è¿è¡Œå™¨"""
    
    def __init__(self, json_dir: str, local_zip_dir: str = None, config: PipelineConfig = None):
        self.config = config or get_config()
        self.json_dir = Path(json_dir)
        
        # æœ¬åœ°ç›®å½•
        base_dir = Path(local_zip_dir) if local_zip_dir else Path(self.config.local_temp_dir)
        self.local_zip_dir = base_dir / "zips"
        self.local_check_dir = base_dir / "check_data"
        self.local_zip_dir.mkdir(parents=True, exist_ok=True)
        self.local_check_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»„ä»¶
        self.downloader = Downloader(self.config.dataweave)
        self.result = PipelineResult()
        self._lock = threading.Lock()
        self._deploy_lock = threading.Lock()
        self._scripts_deployed = False
        self.server_logger: Optional[ServerLogger] = None
        
        # çŠ¶æ€ç®¡ç†å™¨ï¼ˆæ–­ç‚¹ç»­ä¼ æ”¯æŒï¼‰
        self.state_manager = StateManager(base_dir)
    
    def run(self, mode: str = "optimized", workers: int = None):
        """
        è¿è¡Œæµæ°´çº¿
        mode: optimized (ä¸‹è½½å¹¶è¡Œ+æœåŠ¡å™¨ä¸²è¡Œ), parallel (å…¨å¹¶è¡Œ), streaming (æµå¼)
        """
        workers = workers or self.config.max_workers
        
        print()
        print("â•”" + "â•" * 50 + "â•—")
        print(f"â•‘  ğŸ“¦ æ ‡æ³¨æ•°æ®å¤„ç†æµæ°´çº¿ ({mode}æ¨¡å¼)".ljust(51) + "â•‘")
        print("â•š" + "â•" * 50 + "â•")
        print(f"  ğŸ“ JSONç›®å½•: {self.json_dir}")
        
        json_files = list(self.json_dir.glob("*.json"))
        if not json_files:
            print("  âš  æœªæ‰¾åˆ° JSON æ–‡ä»¶")
            return self.result
        
        print(f"  ğŸ“‹ å…± {len(json_files)} ä¸ªæ–‡ä»¶")
        
        with SSHClient() as ssh:
            if not ssh.is_connected:
                print("  âœ— æ— æ³•è¿æ¥æœåŠ¡å™¨")
                return self.result
            
            print(f"  ğŸ”— å·²è¿æ¥æœåŠ¡å™¨: {ssh.server.ip}")
            
            processor = RemoteProcessor(ssh, self.config)
            processor.deploy_scripts()
            
            # åˆå§‹åŒ–æœåŠ¡å™¨æ—¥å¿—
            self.server_logger = ServerLogger(ssh)
            print(f"  ğŸ“‹ æœåŠ¡å™¨æ—¥å¿—: {self.server_logger.log_file}")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            ssh.mkdir_p(ssh.server.zip_dir)
            ssh.mkdir_p(ssh.server.process_dir)
            
            # æ³¨æ„ï¼šä¸å†è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œä»¥æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            # å¦‚éœ€æ¸…ç†ï¼Œè¯·æ‰‹åŠ¨è°ƒç”¨ uploader.cleanup_incomplete(force=True)
            
            # è·å–æœåŠ¡å™¨çŠ¶æ€
            state = processor.get_server_state()
            print(f"  ğŸ“Š æœåŠ¡å™¨: {len(state['zip_files'])} ZIPs / {len(state['processed_dirs'])} å·²å®Œæˆ")
            
            # ç»Ÿè®¡æœ¬åœ°å·²ä¸‹è½½çš„æ–‡ä»¶ï¼ˆåªç»Ÿè®¡æ•°é‡ï¼Œä¸éªŒè¯å®Œæ•´æ€§ï¼‰
            local_zip_files = list(self.local_zip_dir.glob("*.zip"))
            print(f"  ğŸ’¾ æœ¬åœ°ZIP: {len(local_zip_files)} ä¸ª")
            
            # è¿‡æ»¤éœ€è¦å¤„ç†çš„æ–‡ä»¶
            files_to_process = []
            for json_file in json_files:
                stem = json_file.stem
                if stem in state['processed_dirs']:
                    # æœåŠ¡å™¨ä¸Šå·²å®Œæˆçš„æ–‡ä»¶ï¼Œè®°å½•ä¸ºè·³è¿‡
                    self.result.skipped_server_exists.append(stem)
                    self.result.check_passed.append(stem)
                    # è·å–å…³é”®å¸§æ•°é‡
                    kf = processor.get_keyframe_count(f"{ssh.server.final_dir}/{stem}")
                    self.result.keyframe_counts[stem] = kf
                else:
                    files_to_process.append((json_file, stem))
            
            skipped = len(json_files) - len(files_to_process)
            if skipped > 0:
                print(f"  â­ è·³è¿‡(æœåŠ¡å™¨å·²å®Œæˆ): {skipped} ä¸ª")
            
            if not files_to_process:
                print("  âœ“ æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆ")
                self._print_summary()
                # é£ä¹¦è¿½è¸ªï¼šå³ä½¿å…¨éƒ¨è·³è¿‡ä¹Ÿè¦åŒæ­¥
                self._track_to_feishu()
                return self.result
            
            # è®¡ç®—å®é™…éœ€è¦ä¸‹è½½çš„æ•°é‡
            local_stems = set(f.stem for f in local_zip_files)
            need_download = 0
            for json_file, stem in files_to_process:
                zip_name = f"{stem}.zip"
                if zip_name not in state['zip_files'] and stem not in local_stems:
                    need_download += 1
            
            print(f"  ğŸ“¦ å¾…å¤„ç†: {len(files_to_process)} ä¸ª (éœ€ä¸‹è½½: {need_download})")
            print(f"  ğŸ§µ å¹¶å‘æ•°: {workers}")
            print()
            
            if mode == "optimized":
                self._run_optimized(ssh, processor, files_to_process, state, workers)
            elif mode == "parallel":
                self._run_parallel(processor, files_to_process, state, workers)
            else:
                self._run_streaming(ssh, processor, files_to_process, state)
        
        self._print_summary()
        
        # é£ä¹¦è¿½è¸ªï¼šè®°å½•æ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼ˆåŒ…æ‹¬è·³è¿‡çš„ï¼‰
        self._track_to_feishu()
        
        return self.result
    
    def _run_optimized(self, ssh: SSHClient, processor: RemoteProcessor,
                       files: List[tuple], state: Dict, workers: int):
        """ä¼˜åŒ–æ¨¡å¼ï¼šä¸‹è½½å¹¶è¡Œ + æœåŠ¡å™¨æ“ä½œä¸²è¡Œ"""
        
        # é˜¶æ®µ1: å¹¶è¡Œä¸‹è½½
        print("=" * 50)
        print("  ğŸ“¥ é˜¶æ®µ1: å¹¶è¡Œä¸‹è½½ ZIP æ–‡ä»¶")
        print("=" * 50)
        
        files_to_download = []
        skipped_local = 0
        skipped_server = 0
        for json_file, stem in files:
            zip_name = f"{stem}.zip"
            local_zip = self.local_zip_dir / zip_name
            
            if zip_name in state['zip_files']:
                self.result.skipped_server_exists.append(stem)
                skipped_server += 1
                continue
            # åªæ£€æŸ¥æ–‡ä»¶å­˜åœ¨ä¸”å¤§å°>0ï¼Œä¸éªŒè¯å®Œæ•´æ€§ï¼ˆé¿å…å¡é¡¿ï¼‰
            if local_zip.exists() and local_zip.stat().st_size > 0:
                self.result.downloaded.append(stem)
                skipped_local += 1
                continue
            files_to_download.append((stem, zip_name, local_zip))
        
        if skipped_server > 0 or skipped_local > 0:
            print(f"  è·³è¿‡: æœåŠ¡å™¨å·²æœ‰ {skipped_server} ä¸ª, æœ¬åœ°å·²æœ‰ {skipped_local} ä¸ª")
        
        if files_to_download:
            print(f"  éœ€ä¸‹è½½: {len(files_to_download)} ä¸ªæ–‡ä»¶ (å¹¶å‘: {workers})")
            
            # é¢„å…ˆè·å– tokenï¼Œé¿å…åœ¨è¿›åº¦æ¡æ˜¾ç¤ºæœŸé—´è¾“å‡ºæ—¥å¿—
            self.downloader.token_manager.get_token()
            
            # å°è¯•ä½¿ç”¨ tqdm è¿›åº¦æ¡
            try:
                from tqdm import tqdm
                use_tqdm = True
            except ImportError:
                use_tqdm = False
            
            # å¹¶è¡Œä¸‹è½½
            download_status = {}  # stem -> status
            status_lock = threading.Lock()
            active_downloads = {}  # stem -> (downloaded, total)
            
            if use_tqdm:
                # å•è¿›åº¦æ¡ï¼šæ˜¾ç¤ºæ–‡ä»¶æ•° + ä¸‹è½½æµé‡
                file_pbar = tqdm(total=len(files_to_download), desc="  ä¸‹è½½è¿›åº¦", 
                                unit="ä¸ª", ncols=80, leave=True)
                total_bytes = [0]
                downloaded_bytes = [0]
                last_update = [time.time()]
                start_time = [time.time()]
                
                def make_progress_callback(stem):
                    def callback(downloaded, total):
                        with status_lock:
                            if stem not in active_downloads:
                                active_downloads[stem] = (0, total)
                                if total > 0:
                                    total_bytes[0] += total
                            old_downloaded, _ = active_downloads[stem]
                            delta = downloaded - old_downloaded
                            if delta > 0:
                                active_downloads[stem] = (downloaded, total)
                                downloaded_bytes[0] += delta
                                # é™åˆ¶åˆ·æ–°é¢‘ç‡ï¼Œé¿å…é—ªçƒ
                                now = time.time()
                                if now - last_update[0] > 0.2:
                                    last_update[0] = now
                                    # è®¡ç®—ä¸‹è½½é€Ÿåº¦
                                    elapsed = now - start_time[0]
                                    speed = downloaded_bytes[0] / elapsed / 1024 / 1024 if elapsed > 0 else 0
                                    file_pbar.set_postfix_str(f"{downloaded_bytes[0]/1024/1024:.0f}MB {speed:.1f}MB/s", refresh=True)
                    return callback
            else:
                make_progress_callback = lambda stem: None
            
            def download_task(stem, zip_name, local_zip):
                try:
                    progress_cb = make_progress_callback(stem)
                    success = self.downloader.download_file(zip_name, local_zip, progress_callback=progress_cb)
                    with status_lock:
                        download_status[stem] = success
                    return stem, success
                except Exception as e:
                    with status_lock:
                        download_status[stem] = False
                    logger.error(f"ä¸‹è½½å¼‚å¸¸ {stem}: {e}")
                    return stem, False
            
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = [executor.submit(download_task, stem, zip_name, local_zip) 
                          for stem, zip_name, local_zip in files_to_download]
                
                for future in as_completed(futures):
                    stem, success = future.result()
                    if use_tqdm:
                        file_pbar.update(1)
                        status = "âœ“" if success else "âœ—"
                        file_pbar.set_postfix_str(f"{status} {stem[:20]}")
                    else:
                        status = "âœ“" if success else "âœ—"
                        sys.stdout.write(f'\r\033[K  [{len(download_status)}/{len(futures)}] {status} {stem[:40]}')
                        sys.stdout.flush()
                    
                    if success:
                        self.result.downloaded.append(stem)
                    else:
                        self.result.download_failed.append(stem)
            
            if use_tqdm:
                file_pbar.close()
            else:
                print()
            
            # ä¸‹è½½æ±‡æ€»
            success_count = len(self.result.downloaded) - skipped_local
            fail_count = len(self.result.download_failed)
            print(f"  ğŸ“Š ä¸‹è½½å®Œæˆ: âœ“ {success_count}  âœ— {fail_count}")
        else:
            print("  æ‰€æœ‰æ–‡ä»¶å·²ä¸‹è½½æˆ–æœåŠ¡å™¨å·²å­˜åœ¨")
        
        # é˜¶æ®µ2: ä¸²è¡ŒæœåŠ¡å™¨æ“ä½œ
        print()
        print("=" * 50)
        print("  ğŸ”„ é˜¶æ®µ2: ä¸²è¡ŒæœåŠ¡å™¨æ“ä½œ")
        print("=" * 50)
        
        files_for_server = [(jf, stem) for jf, stem in files if stem not in self.result.download_failed]
        
        if not files_for_server:
            print("  æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
            return
        
        # è®¡ç®—å®é™…éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶æ•°é‡ï¼ˆæ’é™¤æœåŠ¡å™¨å·²æœ‰ZIPçš„ï¼‰
        need_upload_count = sum(1 for jf, stem in files_for_server 
                                if f"{stem}.zip" not in state['zip_files'] 
                                and (self.local_zip_dir / f"{stem}.zip").exists())
        
        print(f"  å¾…å¤„ç†: {len(files_for_server)} ä¸ª (éœ€ä¸Šä¼ : {need_upload_count} ä¸ª)")
        
        progress = ProgressTracker(len(files_for_server), "æœåŠ¡å™¨å¤„ç†")
        tracker = Tracker()
        upload_idx = 0
        
        for idx, (json_file, stem) in enumerate(files_for_server, 1):
            zip_name = f"{stem}.zip"
            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¸Šä¼ 
            need_upload = zip_name not in state['zip_files'] and (self.local_zip_dir / zip_name).exists()
            if need_upload:
                upload_idx += 1
                success = self._process_single(ssh, processor, json_file, stem, state, upload_idx, need_upload_count)
            else:
                success = self._process_single(ssh, processor, json_file, stem, state, 0, 0)
            progress.update(success=success, name=stem)
            
            # æ¯å®Œæˆä¸€ä¸ªæ•°æ®åŒ…ç«‹å³åŒæ­¥é£ä¹¦
            if success and stem in self.result.moved_to_final:
                self._track_single_to_feishu(tracker, stem)
        
        progress.summary()
    
    def _run_parallel(self, processor: RemoteProcessor, files: List[tuple], 
                      state: Dict, workers: int):
        """å…¨å¹¶è¡Œæ¨¡å¼ï¼šä½¿ç”¨è¿æ¥æ± å¤ç”¨ SSH è¿æ¥"""
        progress = ProgressTracker(len(files), "å¹¶è¡Œå¤„ç†")
        pool = SSHConnectionPool(size=workers)
        
        try:
            with ThreadPoolExecutor(max_workers=workers) as executor:
                futures = {}
                for json_file, stem in files:
                    future = executor.submit(
                        self._process_with_pool, 
                        pool, json_file, stem, state
                    )
                    futures[future] = stem
                
                for future in as_completed(futures):
                    stem = futures[future]
                    try:
                        success = future.result()
                        progress.update(success=success, name=stem)
                    except Exception as e:
                        logger.error(f"å¹¶è¡Œå¤„ç†å¼‚å¸¸ {stem}: {e}")
                        progress.update(success=False, name=f"{stem} (å¼‚å¸¸)")
        finally:
            pool.close_all()
        
        progress.summary()
    
    def _run_streaming(self, ssh: SSHClient, processor: RemoteProcessor,
                       files: List[tuple], state: Dict):
        """æµå¼æ¨¡å¼ï¼šä¸‹è½½ä¸€ä¸ªå¤„ç†ä¸€ä¸ªï¼Œæ¯å®Œæˆä¸€ä¸ªç«‹å³åŒæ­¥é£ä¹¦"""
        progress = ProgressTracker(len(files), "æµå¼å¤„ç†")
        total_count = len(files)
        tracker = Tracker()
        
        for idx, (json_file, stem) in enumerate(files, 1):
            success = self._process_single(ssh, processor, json_file, stem, state, idx, total_count)
            progress.update(success=success, name=stem)
            
            # æ¯å®Œæˆä¸€ä¸ªæ•°æ®åŒ…ç«‹å³åŒæ­¥é£ä¹¦
            if success and stem in self.result.moved_to_final:
                self._track_single_to_feishu(tracker, stem)
        
        progress.summary()
    
    def _process_single(self, ssh: SSHClient, processor: RemoteProcessor,
                        json_file: Path, stem: str, state: Dict,
                        current_idx: int = 0, total_count: int = 0) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆä½¿ç”¨å…±äº«SSHè¿æ¥ï¼‰"""
        zip_name = f"{stem}.zip"
        local_zip = self.local_zip_dir / zip_name
        server = ssh.server
        remote_zip = f"{server.zip_dir}/{zip_name}"
        
        # è¿›åº¦å‰ç¼€
        progress_prefix = f"[{current_idx}/{total_count}] " if total_count > 0 else ""
        
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»ä¸­é—´çŠ¶æ€æ¢å¤
            skip_download = self.state_manager.can_skip_download(stem)
            skip_upload = self.state_manager.can_skip_upload(stem)
            
            # æ£€æŸ¥ process_dir ä¸­æ˜¯å¦å·²æœ‰è§£å‹çš„æ•°æ®
            in_processing = stem in state.get('processing_dirs', set())
            
            # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆä¸éªŒè¯å®Œæ•´æ€§ï¼Œé¿å…å¡é¡¿ï¼‰
            local_exists = local_zip.exists() and local_zip.stat().st_size > 0
            
            # ä¸‹è½½ï¼ˆåªåœ¨æœ¬åœ°ä¸å­˜åœ¨ä¸”æœåŠ¡å™¨ä¹Ÿæ²¡æœ‰æ—¶æ‰ä¸‹è½½ï¼‰
            if not skip_download and zip_name not in state['zip_files'] and not local_exists:
                if not self.downloader.download_file(zip_name, local_zip):
                    self.result.log_error(stem, "ä¸‹è½½", "ä¸‹è½½å¤±è´¥")
                    self.result.check_failed.append(stem)
                    self.state_manager.update(stem, ProcessStatus.FAILED, "ä¸‹è½½å¤±è´¥")
                    return False
                self.result.downloaded.append(stem)
                self.state_manager.update(stem, ProcessStatus.DOWNLOADED)
            
            # ä¸Šä¼ 
            if not skip_upload and zip_name not in state['zip_files'] and local_zip.exists():
                # åˆ›å»ºä¸Šä¼ è¿›åº¦å›è°ƒ
                file_size = local_zip.stat().st_size
                upload_start = [time.time()]
                last_print = [0]
                
                def upload_progress(transferred, total):
                    now = time.time()
                    if now - last_print[0] < 0.3:  # é™åˆ¶åˆ·æ–°é¢‘ç‡
                        return
                    last_print[0] = now
                    elapsed = now - upload_start[0]
                    speed = transferred / elapsed / 1024 / 1024 if elapsed > 0 else 0
                    percent = transferred / total * 100 if total > 0 else 0
                    sys.stdout.write(f'\r\033[K  {progress_prefix}â¬† ä¸Šä¼  {stem[:20]}: {transferred/1024/1024:.1f}/{total/1024/1024:.1f}MB ({percent:.0f}%) {speed:.1f}MB/s')
                    sys.stdout.flush()
                
                if not ssh.upload_file(str(local_zip), remote_zip, progress_callback=upload_progress):
                    print()  # æ¢è¡Œ
                    self.result.log_error(stem, "ä¸Šä¼ ", "ä¸Šä¼ å¤±è´¥")
                    self.result.check_failed.append(stem)
                    self.state_manager.update(stem, ProcessStatus.FAILED, "ä¸Šä¼ å¤±è´¥")
                    return False
                print()  # æ¢è¡Œ
                self.result.uploaded.append(stem)
                self.state_manager.update(stem, ProcessStatus.UPLOADED)
            
            # å¤„ç†ï¼ˆå¦‚æœ process_dir ä¸­å·²æœ‰æ•°æ®åˆ™è·³è¿‡ï¼‰
            if not in_processing:
                success, err = processor.process_zip(remote_zip, str(json_file), stem)
                if not success:
                    self.result.log_error(stem, "å¤„ç†", err)
                    self.result.check_failed.append(stem)
                    self.state_manager.update(stem, ProcessStatus.FAILED, err)
                    return False
            self.result.processed.append(stem)
            self.state_manager.update(stem, ProcessStatus.PROCESSED)
            
            # æ£€æŸ¥
            data_dir = f"{server.process_dir}/{stem}"
            passed, issue_count, report = processor.check_annotations(data_dir, stem)
            
            # è·å–å…³é”®å¸§æ•°é‡
            kf = processor.get_keyframe_count(data_dir)
            self.result.keyframe_counts[stem] = kf
            
            if not passed:
                self.result.log_error(stem, "æ£€æŸ¥", f"å‘ç° {issue_count} ä¸ªé—®é¢˜å¸§")
                self.result.check_failed.append(stem)
                self.state_manager.update(stem, ProcessStatus.CHECKED, f"æ£€æŸ¥å¤±è´¥: {issue_count} ä¸ªé—®é¢˜å¸§")
                # ä¸‹è½½æŠ¥å‘Š
                local_report = self.local_check_dir / f"report_{stem}.txt"
                ssh.download_file(report, str(local_report))
                return False
            
            self.result.check_passed.append(stem)
            self.state_manager.update(stem, ProcessStatus.CHECKED)
            
            # ç§»åŠ¨
            success, dst = processor.move_to_final(stem)
            if success:
                self.result.moved_to_final.append(stem)
                # æ¸…ç†æœ¬åœ°ZIP
                if local_zip.exists():
                    local_zip.unlink()
                # è®°å½•æœåŠ¡å™¨æ—¥å¿—
                if self.server_logger:
                    self.server_logger.log_success(stem, kf)
                # æ ‡è®°å®Œæˆ
                self.state_manager.update(stem, ProcessStatus.COMPLETED)
            else:
                self.result.log_error(stem, "ç§»åŠ¨", dst)
            
            return True
            
        except Exception as e:
            self.result.log_error(stem, "å¼‚å¸¸", str(e))
            self.result.check_failed.append(stem)
            self.state_manager.update(stem, ProcessStatus.FAILED, str(e))
            # è®°å½•å¤±è´¥æ—¥å¿—
            if self.server_logger:
                self.server_logger.log_failure(stem, str(e))
            return False
    
    def _process_with_pool(self, pool: SSHConnectionPool, json_file: Path, 
                           stem: str, state: Dict) -> bool:
        """ä½¿ç”¨è¿æ¥æ± å¤„ç†å•ä¸ªæ–‡ä»¶"""
        ssh = None
        try:
            ssh = pool.get()
            if not ssh or not ssh.is_connected:
                self.result.log_error(stem, "è¿æ¥", "æ— æ³•è·å–SSHè¿æ¥")
                with self._lock:
                    self.result.check_failed.append(stem)
                return False
            
            processor = RemoteProcessor(ssh, self.config)
            
            # çº¿ç¨‹å®‰å…¨çš„è„šæœ¬éƒ¨ç½²ï¼ˆåªéƒ¨ç½²ä¸€æ¬¡ï¼‰
            with self._deploy_lock:
                if not self._scripts_deployed:
                    processor.deploy_scripts()
                    self._scripts_deployed = True
            
            return self._process_single(ssh, processor, json_file, stem, state)
        finally:
            if ssh:
                pool.put(ssh)
    
    def _process_single_threaded(self, json_file: Path, stem: str, state: Dict) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆç‹¬ç«‹SSHè¿æ¥ï¼Œç”¨äºå¹¶è¡Œæ¨¡å¼ï¼‰- å·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹"""
        with SSHClient() as ssh:
            if not ssh.is_connected:
                self.result.log_error(stem, "è¿æ¥", "SSHè¿æ¥å¤±è´¥")
                with self._lock:
                    self.result.check_failed.append(stem)
                return False
            
            processor = RemoteProcessor(ssh, self.config)
            processor.deploy_scripts()
            return self._process_single(ssh, processor, json_file, stem, state)
    
    def _print_summary(self):
        """æ‰“å°æ‰§è¡Œæ±‡æ€»"""
        print()
        print("â•”" + "â•" * 50 + "â•—")
        print("â•‘  ğŸ“Š æ‰§è¡Œæ±‡æ€»".ljust(51) + "â•‘")
        print("â• " + "â•" * 50 + "â•£")
        
        stats = [
            ("â­ è·³è¿‡(å·²å­˜åœ¨)", len(self.result.skipped_server_exists)),
            ("â¬‡ ä¸‹è½½æˆåŠŸ", len(self.result.downloaded)),
            ("â¬‡ ä¸‹è½½å¤±è´¥", len(self.result.download_failed)),
            ("â¬† ä¸Šä¼ æˆåŠŸ", len(self.result.uploaded)),
            ("âš™ å¤„ç†æˆåŠŸ", len(self.result.processed)),
            ("âœ“ æ£€æŸ¥é€šè¿‡", len(self.result.check_passed)),
            ("âœ— æ£€æŸ¥å¤±è´¥", len(self.result.check_failed)),
            ("ğŸ“ å·²ç§»åŠ¨", len(self.result.moved_to_final)),
        ]
        
        total_kf = sum(self.result.keyframe_counts.values())
        if total_kf > 0:
            stats.append(("ğŸ“Š æ€»å…³é”®å¸§", total_kf))
        
        for label, count in stats:
            line = f"â•‘  {label}: {count}"
            print(line.ljust(51) + "â•‘")
        
        print("â•š" + "â•" * 50 + "â•")
        
        if self.result.check_failed:
            print()
            print("  âš  æ£€æŸ¥æœªé€šè¿‡çš„æ•°æ®:")
            for name in self.result.check_failed:
                print(f"    â€¢ {name}")
        
        if self.result.errors:
            print()
            print("  âŒ å¤±è´¥è¯¦æƒ…:")
            for stem, error_list in self.result.errors.items():
                print(f"    â”Œâ”€ {stem}")
                for step, msg in error_list:
                    display_msg = msg[:60] + "..." if len(msg) > 60 else msg
                    print(f"    â”‚  [{step}] {display_msg}")
                print(f"    â””â”€")
    
    def _track_single_to_feishu(self, tracker: Tracker, stem: str):
        """å•ä¸ªæ•°æ®åŒ…å®Œæˆåç«‹å³åŒæ­¥é£ä¹¦"""
        try:
            kf = self.result.keyframe_counts.get(stem, 0)
            status = "å·²å®Œæˆ" if stem in self.result.check_passed else "æ£€æŸ¥ä¸é€šè¿‡"
            uploaded = stem in self.result.moved_to_final
            
            record = TrackingRecord(
                name=stem,
                keyframe_count=kf,
                annotation_status=status,
                uploaded=uploaded,
            )
            
            result = tracker.track([record], str(self.json_dir))
            if result:
                print(f"  ğŸ“¤ é£ä¹¦å·²åŒæ­¥: {stem}")
        except Exception as e:
            logger.warning(f"é£ä¹¦åŒæ­¥å¤±è´¥ {stem}: {e}")
    
    def _track_to_feishu(self):
        """å°†å¤„ç†ç»“æœåŒæ­¥åˆ°é£ä¹¦è¡¨æ ¼ï¼ˆåŒ…æ‹¬è·³è¿‡çš„æ–‡ä»¶ï¼‰"""
        try:
            tracker = Tracker()
            
            # æ”¶é›†éœ€è¦åŒæ­¥çš„è®°å½•ï¼ˆæ’é™¤æµå¼æ¨¡å¼ä¸­å·²åŒæ­¥çš„ï¼‰
            records = []
            all_names = set()
            all_names.update(self.result.skipped_server_exists)
            all_names.update(self.result.check_failed)
            
            for name in sorted(all_names):
                status = "å·²å®Œæˆ" if name in self.result.check_passed else "æ£€æŸ¥ä¸é€šè¿‡"
                uploaded = name in self.result.moved_to_final or name in self.result.skipped_server_exists
                records.append(TrackingRecord(
                    name=name,
                    keyframe_count=self.result.keyframe_counts.get(name, 0),
                    annotation_status=status,
                    uploaded=uploaded,
                ))
            
            if not records:
                return
            
            print()
            print(f"  ğŸ“¤ åŒæ­¥åˆ°é£ä¹¦: {len(records)} æ¡è®°å½•...")
            
            result = tracker.track(records, str(self.json_dir))
            
            if result:
                created = result.get('created', 0)
                updated = result.get('updated', 0)
                if isinstance(created, list):
                    created = len(created)
                if isinstance(updated, list):
                    updated = len(updated)
                print(f"  âœ… é£ä¹¦åŒæ­¥å®Œæˆ: æ–°å¢ {created}, æ›´æ–° {updated}")
        except Exception as e:
            logger.warning(f"é£ä¹¦è¿½è¸ªå¤±è´¥: {e}")
            print(f"  âš  é£ä¹¦åŒæ­¥å¤±è´¥: {e}")
