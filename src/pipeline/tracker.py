"""
è¿½è¸ªæ¨¡å—
è´Ÿè´£é£ä¹¦è¡¨æ ¼è¿½è¸ªå’Œæœ¬åœ°ç»Ÿè®¡
"""
import os
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime

import yaml
import requests

logger = logging.getLogger(__name__)


@dataclass
class TrackingRecord:
    """è¿½è¸ªè®°å½•"""
    name: str
    keyframe_count: int = 0
    annotation_status: str = "å·²å®Œæˆ"
    uploaded: bool = False
    attributes: List[str] = None
    
    def __post_init__(self):
        if self.attributes is None:
            self.attributes = []


class BaseTracker:
    """è¿½è¸ªå™¨åŸºç±»"""
    
    def track(self, records: List[TrackingRecord]) -> Dict[str, Any]:
        """è¿½è¸ªè®°å½•"""
        raise NotImplementedError
    
    def detect_attributes(self, json_dir: str) -> List[str]:
        """æ£€æµ‹æ•°æ®å±æ€§"""
        return []


class LocalTracker(BaseTracker):
    """æœ¬åœ° TXT è¿½è¸ªå™¨"""
    
    def __init__(self, output_path: str = "local_report.txt"):
        self.output_path = Path(output_path)
    
    def track(self, records: List[TrackingRecord]) -> Dict[str, Any]:
        """å†™å…¥æœ¬åœ° TXT æŠ¥å‘Š"""
        with open(self.output_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("æ ‡æ³¨æ•°æ®å¤„ç†ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            total_keyframes = 0
            for rec in records:
                f.write(f"æ•°æ®åŒ…: {rec.name}\n")
                f.write(f"  å…³é”®å¸§æ•°: {rec.keyframe_count}\n")
                f.write(f"  æ ‡æ³¨æƒ…å†µ: {rec.annotation_status}\n")
                f.write(f"  å·²ä¸Šä¼ : {'æ˜¯' if rec.uploaded else 'å¦'}\n")
                if rec.attributes:
                    f.write(f"  å±æ€§: {', '.join(rec.attributes)}\n")
                f.write("\n")
                total_keyframes += rec.keyframe_count
            
            f.write("-" * 60 + "\n")
            f.write(f"æ€»è®¡: {len(records)} ä¸ªæ•°æ®åŒ…, {total_keyframes} ä¸ªå…³é”®å¸§\n")
        
        logger.info(f"âœ… æœ¬åœ°æŠ¥å‘Šå·²ä¿å­˜: {self.output_path}")
        
        return {
            "created": len(records),
            "updated": 0,
            "total_keyframes": total_keyframes,
        }


class FeishuTracker(BaseTracker):
    """é£ä¹¦å¤šç»´è¡¨æ ¼è¿½è¸ªå™¨ï¼ˆç›´æ¥è°ƒç”¨é£ä¹¦ APIï¼‰"""
    
    def __init__(self, config_path: str = "configs/feishu.yaml"):
        self.config_path = Path(config_path)
        self.config: Dict = {}
        self._token: Optional[str] = None
        self._token_time: Optional[float] = None
        self._available = False
        self._init_config()
    
    def _init_config(self):
        """åŠ è½½é…ç½®"""
        try:
            if not self.config_path.exists():
                logger.warning(f"é£ä¹¦é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
                return
            
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f) or {}
            
            # ä»ç¯å¢ƒå˜é‡è·å–æ•æ„Ÿä¿¡æ¯
            self.config['app_id'] = os.environ.get('FEISHU_APP_ID', '')
            self.config['app_secret'] = os.environ.get('FEISHU_APP_SECRET', '')
            
            if self.config.get('app_id') and self.config.get('app_secret'):
                self._available = True
                logger.info("ğŸ”— é£ä¹¦è¿½è¸ªå™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("é£ä¹¦å‡­è¯æœªé…ç½® (FEISHU_APP_ID/FEISHU_APP_SECRET)")
        except Exception as e:
            logger.warning(f"é£ä¹¦é…ç½®åŠ è½½å¤±è´¥: {e}")
    
    @property
    def is_available(self) -> bool:
        return self._available and self.config.get('enabled', True)
    
    def _get_token(self) -> str:
        """è·å– tenant_access_token"""
        if self._token and self._token_time:
            if time.time() - self._token_time < 7000:
                return self._token
        
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        payload = {
            "app_id": self.config.get('app_id', ''),
            "app_secret": self.config.get('app_secret', '')
        }
        
        try:
            r = requests.post(url, json=payload, timeout=10)
            data = r.json()
            if data.get('code') == 0:
                self._token = data.get('tenant_access_token')
                self._token_time = time.time()
                return self._token
        except Exception as e:
            logger.error(f"è·å–é£ä¹¦ Token å¤±è´¥: {e}")
        return ""
    
    def _get_headers(self) -> Dict[str, str]:
        return {
            "Authorization": f"Bearer {self._get_token()}",
            "Content-Type": "application/json"
        }
    
    def _search_record(self, name: str) -> Optional[str]:
        """æ ¹æ®æ•°æ®åŒ…åç§°æœç´¢è®°å½•ï¼Œè¿”å› record_id"""
        app_token = self.config.get('app_token', '')
        table_id = self.config.get('table_id', '')
        
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/search"
        payload = {
            "filter": {
                "conjunction": "and",
                "conditions": [{
                    "field_name": "æ•°æ®åŒ…åç§°",
                    "operator": "is",
                    "value": [name]
                }]
            },
            "page_size": 1
        }
        
        try:
            r = requests.post(url, json=payload, headers=self._get_headers(), timeout=15)
            data = r.json()
            if data.get('code') == 0:
                items = data.get('data', {}).get('items', [])
                if items:
                    return items[0].get('record_id')
        except Exception:
            pass
        return None
    
    def _batch_create_records(self, records_fields: List[Dict]) -> int:
        """æ‰¹é‡åˆ›å»ºè®°å½•"""
        app_token = self.config.get('app_token', '')
        table_id = self.config.get('table_id', '')
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/batch_create"
        
        payload = {"records": [{"fields": f} for f in records_fields]}
        try:
            r = requests.post(url, json=payload, headers=self._get_headers(), timeout=30)
            data = r.json()
            if data.get('code') == 0:
                return len(data.get('data', {}).get('records', []))
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ›å»ºå¤±è´¥: {e}")
        return 0
    
    def _batch_update_records(self, records: List[Dict]) -> int:
        """æ‰¹é‡æ›´æ–°è®°å½•"""
        app_token = self.config.get('app_token', '')
        table_id = self.config.get('table_id', '')
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/batch_update"
        
        payload = {"records": records}
        try:
            r = requests.post(url, json=payload, headers=self._get_headers(), timeout=30)
            data = r.json()
            if data.get('code') == 0:
                return len(records)
        except Exception as e:
            logger.error(f"æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
        return 0
    
    def detect_attributes(self, json_dir: str) -> List[str]:
        """ä»è·¯å¾„ä¸­æ£€æµ‹æ•°æ®å±æ€§"""
        attributes = []
        keywords = self.config.get('attribute_keywords', {})
        path_str = str(json_dir).lower()
        
        for attr_name, keywords_list in keywords.items():
            for keyword in keywords_list:
                if keyword.lower() in path_str:
                    attributes.append(attr_name)
                    break
        return attributes
    
    def track(self, records: List[TrackingRecord], json_dir: str = None) -> Dict[str, Any]:
        """è¿½è¸ªåˆ°é£ä¹¦è¡¨æ ¼"""
        if not self.is_available:
            logger.warning("é£ä¹¦è¿½è¸ªå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡")
            return {}
        
        attributes = self.detect_attributes(json_dir) if json_dir else []
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        to_create = []
        to_update = []
        created_names = []
        updated_names = []
        total_keyframes = 0
        
        for rec in records:
            total_keyframes += rec.keyframe_count
            
            fields = {
                "æ•°æ®åŒ…åç§°": rec.name,
                "æ ‡æ³¨æƒ…å†µ": rec.annotation_status,
                "å…³é”®å¸§æ•°": rec.keyframe_count,
                "æ›´æ–°æ—¶é—´": now,
            }
            
            # æ·»åŠ å±æ€§
            for attr in attributes:
                attr_field = f"{attr}å±æ€§"
                if attr_field in self.config.get('field_mapping', {}):
                    fields[attr_field] = True
            
            # ä¸Šä¼ çŠ¶æ€
            if rec.uploaded:
                fields['ä¸Šä¼ data02/dataset/scenesnew'] = True
            
            # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨
            record_id = self._search_record(rec.name)
            
            if record_id:
                to_update.append({"record_id": record_id, "fields": fields})
                updated_names.append(rec.name)
            else:
                to_create.append(fields)
                created_names.append(rec.name)
        
        # æ‰§è¡Œæ‰¹é‡æ“ä½œï¼ˆé£ä¹¦é™åˆ¶æ¯æ‰¹ 500 æ¡ï¼‰
        created_count = 0
        updated_count = 0
        
        for i in range(0, len(to_create), 500):
            batch = to_create[i:i+500]
            created_count += self._batch_create_records(batch)
            if i + 500 < len(to_create):
                time.sleep(0.5)
        
        for i in range(0, len(to_update), 500):
            batch = to_update[i:i+500]
            updated_count += self._batch_update_records(batch)
            if i + 500 < len(to_update):
                time.sleep(0.5)
        
        logger.info(f"âœ… é£ä¹¦æ›´æ–°: æ–°å¢ {created_count}, æ›´æ–° {updated_count}, å…³é”®å¸§ {total_keyframes}")
        
        return {
            'created': created_names,
            'updated': updated_names,
            'total_keyframes': total_keyframes
        }


class Tracker:
    """ç»Ÿä¸€è¿½è¸ªå™¨ï¼Œè‡ªåŠ¨é€‰æ‹©é£ä¹¦æˆ–æœ¬åœ°"""
    
    def __init__(self, feishu_config: str = "configs/feishu.yaml"):
        self.feishu = FeishuTracker(feishu_config)
        self.local = LocalTracker()
        self._use_feishu = self.feishu.is_available
    
    def track(self, records: List[TrackingRecord], json_dir: str = None) -> Dict[str, Any]:
        """è¿½è¸ªè®°å½•"""
        if self._use_feishu:
            return self.feishu.track(records, json_dir)
        else:
            return self.local.track(records)
    
    def detect_attributes(self, json_dir: str) -> List[str]:
        """æ£€æµ‹æ•°æ®å±æ€§"""
        if self._use_feishu:
            return self.feishu.detect_attributes(json_dir)
        return []


def create_tracking_records(result, keyframe_counts: Dict[str, int]) -> List[TrackingRecord]:
    """ä» PipelineResult åˆ›å»ºè¿½è¸ªè®°å½•"""
    records = []
    
    # æ”¶é›†æ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®åç§°
    all_names = set()
    all_names.update(result.downloaded)
    all_names.update(result.uploaded)
    all_names.update(result.processed)
    all_names.update(result.check_passed)
    all_names.update(result.check_failed)
    all_names.update(result.moved_to_final)
    all_names.update(result.skipped_server_exists)
    
    for name in sorted(all_names):
        # ç¡®å®šæ ‡æ³¨çŠ¶æ€
        if name in result.check_passed or name in result.skipped_server_exists:
            status = "å·²å®Œæˆ"
        elif name in result.check_failed:
            status = "æ£€æŸ¥ä¸é€šè¿‡"
        else:
            status = "å·²å®Œæˆ"
        
        # æ˜¯å¦å·²ä¸Šä¼ 
        uploaded = name in result.moved_to_final or name in result.skipped_server_exists
        
        records.append(TrackingRecord(
            name=name,
            keyframe_count=keyframe_counts.get(name, 0),
            annotation_status=status,
            uploaded=uploaded,
        ))
    
    return records
