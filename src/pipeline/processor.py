"""
æœåŠ¡å™¨ç«¯å¤„ç†æ¨¡å—
è´Ÿè´£åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè§£å‹ ZIPã€æ›¿æ¢ JSONã€æ£€æŸ¥è´¨é‡
"""
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime

from .config import get_config, PipelineConfig
from .ssh_client import SSHClient

logger = logging.getLogger(__name__)

# è¿œç¨‹è„šæœ¬è·¯å¾„
REMOTE_WORKER_SCRIPT = "/tmp/zip_worker.py"
REMOTE_CHECKER_SCRIPT = "/tmp/annotation_checker.py"
REMOTE_CHECK_CONFIG = "/tmp/check_config.yaml"

# æœ¬åœ°è„šæœ¬ç›®å½•
LOCAL_SCRIPTS_DIR = Path(__file__).parent.parent / "remote_scripts"


def _load_script(name: str) -> str:
    """ä» remote_scripts ç›®å½•åŠ è½½è„šæœ¬å†…å®¹"""
    script_path = LOCAL_SCRIPTS_DIR / name
    if script_path.exists():
        return script_path.read_text(encoding='utf-8')
    raise FileNotFoundError(f"è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_path}")


class RemoteProcessor:
    """è¿œç¨‹æœåŠ¡å™¨å¤„ç†å™¨"""
    
    def __init__(self, ssh: SSHClient, config: PipelineConfig = None):
        self.ssh = ssh
        self.config = config or get_config()
        self._scripts_deployed = False
    
    def deploy_scripts(self):
        """éƒ¨ç½²è¿œç¨‹å¤„ç†è„šæœ¬"""
        if self._scripts_deployed:
            return
        
        # éƒ¨ç½² ZIP å¤„ç†è„šæœ¬
        self.ssh.write_file(REMOTE_WORKER_SCRIPT, _load_script("zip_worker.py"))
        
        # éƒ¨ç½²æ£€æŸ¥è„šæœ¬
        self.ssh.write_file(REMOTE_CHECKER_SCRIPT, _load_script("annotation_checker.py"))
        
        # ä¸Šä¼ æ£€æŸ¥é…ç½®
        config_path = Path(self.config.check_config_path)
        if config_path.exists():
            import yaml
            with open(config_path, 'r') as f:
                config_content = yaml.dump(yaml.safe_load(f))
            self.ssh.write_file(REMOTE_CHECK_CONFIG, config_content)
        
        self._scripts_deployed = True
        logger.info("âœ… è¿œç¨‹è„šæœ¬éƒ¨ç½²å®Œæˆ")
    
    def get_server_state(self) -> Dict:
        """è·å–æœåŠ¡å™¨çŠ¶æ€"""
        server = self.ssh.server
        
        # è·å–å·²æœ‰çš„ ZIP æ–‡ä»¶
        zip_files = set()  # å­˜å‚¨æ ‡å‡†åŒ–çš„æ–‡ä»¶åï¼ˆä¸å¸¦processed_å‰ç¼€ï¼‰
        zip_file_map = {}  # æ ‡å‡†æ–‡ä»¶å -> å®é™…æ–‡ä»¶åçš„æ˜ å°„
        files = self.ssh.list_files(server.zip_dir, "*.zip")
        for name in files:
            if name.startswith("processed_"):
                # å»æ‰ processed_ å‰ç¼€å¾—åˆ°æ ‡å‡†æ–‡ä»¶å
                standard_name = name[len("processed_"):]
                zip_files.add(standard_name)
                zip_file_map[standard_name] = name
            else:
                # æ–‡ä»¶åæœ¬èº«å°±æ˜¯æ ‡å‡†å
                zip_files.add(name)
                zip_file_map[name] = name
        
        # è·å–å·²å¤„ç†å®Œæˆçš„ç›®å½•ï¼ˆåªæ£€æŸ¥å½“å‰ final_dirï¼‰
        processed_dirs = set(self.ssh.list_dirs(server.final_dir))
        
        # è·å–å¤„ç†ä¸­çš„ç›®å½•ï¼ˆæ–­ç‚¹ç»­ä¼ æ”¯æŒï¼‰
        processing_dirs = set(self.ssh.list_dirs(server.process_dir))
        
        return {
            "zip_files": zip_files,
            "zip_file_map": zip_file_map,
            "processed_dirs": processed_dirs,
            "processing_dirs": processing_dirs,
        }
    
    def process_zip(self, zip_path: str, json_path: str, stem: str) -> Tuple[bool, str]:
        """
        åœ¨æœåŠ¡å™¨ä¸Šå¤„ç† ZIP æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ ZIPï¼‰æˆ–ä»…å¤„ç† JSON
        è¿”å› (success, error_message)
        """
        server = self.ssh.server
        
        # ä¸Šä¼  JSON æ–‡ä»¶
        remote_json = f"/tmp/{Path(json_path).name}"
        if not self.ssh.file_exists(remote_json):
            if not self.ssh.upload_file(json_path, remote_json):
                return False, "ä¸Šä¼  JSON æ–‡ä»¶å¤±è´¥"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ ZIP æ–‡ä»¶
        has_zip = self.ssh.file_exists(zip_path)
        
        if has_zip:
            # æœ‰ ZIP æ–‡ä»¶ï¼šè§£å‹å¹¶å¤„ç†
            logger.info(f"[{stem}] ğŸ“¦ è§£å‹ZIP...")
            
            # å°è¯•ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
            try:
                from tqdm import tqdm
                import threading
                import sys
                
                # åˆ›å»ºä¸ç¡®å®šè¿›åº¦æ¡
                pbar = tqdm(desc=f"  è§£å‹ {stem[:20]}", bar_format='{desc}: {elapsed}', ncols=60, file=sys.stdout)
                
                # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè§£å‹å‘½ä»¤
                result = [None, None, None]  # [status, out, err]
                
                def extract_task():
                    cmd = (
                        f"python3 {REMOTE_WORKER_SCRIPT} "
                        f"--zip '{zip_path}' "
                        f"--json '{remote_json}' "
                        f"--out '{server.process_dir}' "
                        f"--output_name '{stem}' "
                        f"--rename_json '{self.config.rename_json}'"
                    )
                    status, out, err = self.ssh.exec_command(cmd, timeout=300)
                    result[0], result[1], result[2] = status, out, err
                
                thread = threading.Thread(target=extract_task)
                thread.start()
                
                # ç­‰å¾…çº¿ç¨‹å®Œæˆï¼ŒåŒæ—¶æ›´æ–°è¿›åº¦æ¡
                while thread.is_alive():
                    pbar.update(0)  # è§¦å‘åˆ·æ–°
                    thread.join(timeout=0.5)
                
                pbar.close()
                status, out, err = result
                
            except ImportError:
                # å¦‚æœæ²¡æœ‰tqdmï¼Œç›´æ¥æ‰§è¡Œ
                cmd = (
                    f"python3 {REMOTE_WORKER_SCRIPT} "
                    f"--zip '{zip_path}' "
                    f"--json '{remote_json}' "
                    f"--out '{server.process_dir}' "
                    f"--output_name '{stem}' "
                    f"--rename_json '{self.config.rename_json}'"
                )
                status, out, err = self.ssh.exec_command(cmd, timeout=300)
            
            if status != 0:
                return False, f"å¤„ç†è„šæœ¬å¤±è´¥: {err}"
            
            logger.info(f"[{stem}] âœ“ è§£å‹å®Œæˆ")
        else:
            # æ²¡æœ‰ ZIP æ–‡ä»¶ï¼šä»…å¤„ç† JSON
            target_dir = f"{server.process_dir}/{stem}"
            self.ssh.mkdir_p(target_dir)
            
            # ç¡®å®š JSON æ–‡ä»¶å
            json_filename = "annotations.json" if self.config.rename_json else Path(json_path).name
            target_json = f"{target_dir}/{json_filename}"
            
            # å¤åˆ¶ JSON åˆ°ç›®æ ‡ä½ç½®
            status, _, err = self.ssh.exec_command(f"cp '{remote_json}' '{target_json}'")
            if status != 0:
                return False, f"å¤åˆ¶ JSON å¤±è´¥: {err}"
        
        return True, ""
    
    def check_annotations(self, data_dir: str, stem: str) -> Tuple[bool, int, str]:
        """
        æ£€æŸ¥æ ‡æ³¨è´¨é‡
        è¿”å› (passed, issue_count, report_path)
        """
        server = self.ssh.server
        # æŠ¥å‘Šå­˜æ”¾åœ¨æœåŠ¡å™¨ç«¯ process_dir/reports/ ç›®å½•
        reports_dir = f"{server.process_dir}/reports"
        self.ssh.mkdir_p(reports_dir)
        report_path = f"{reports_dir}/report_{stem}.txt"
        
        cmd = (
            f"python3 {REMOTE_CHECKER_SCRIPT} "
            f"--data_dir '{data_dir}' "
            f"--config '{REMOTE_CHECK_CONFIG}' "
            f"--report '{report_path}'"
        )
        
        status, out, err = self.ssh.exec_command(cmd, timeout=120)
        
        if status != 0:
            return False, -1, f"æ£€æŸ¥è„šæœ¬å¤±è´¥: {err[:200]}"
        
        # è¯»å–æŠ¥å‘Šåˆ¤æ–­æ˜¯å¦é€šè¿‡
        report_content = self.ssh.read_file(report_path) or ""
        issue_count = report_content.count("å¸§:")
        
        return issue_count == 0, issue_count, report_path
    
    def get_keyframe_count(self, data_dir: str) -> int:
        """è·å–å…³é”®å¸§æ•°é‡"""
        # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„ JSON æ–‡ä»¶ä½ç½®
        sample_paths = [
            f"{data_dir}/sample.json",
            f"{data_dir}/undistorted/sample.json",
            f"{data_dir}/annotations.json",  # JSON-only æ¨¡å¼
        ]
        
        logger.debug(f"ğŸ” æ£€æŸ¥å…³é”®å¸§: {data_dir}")
        
        for sample_path in sample_paths:
            if self.ssh.file_exists(sample_path):
                logger.debug(f"  âœ“ æ‰¾åˆ°: {sample_path}")
                # å°è¯•å¤šç§ JSON æ ¼å¼
                cmd = (
                    f"python3 -c \""
                    f"import json; "
                    f"data = json.load(open('{sample_path}')); "
                    f"print(len(data['frames']) if isinstance(data, dict) and 'frames' in data else len(data))"
                    f"\""
                )
                status, out, err = self.ssh.exec_command(cmd)
                if status == 0 and out.strip().isdigit():
                    count = int(out.strip())
                    logger.debug(f"  âœ“ å…³é”®å¸§æ•°: {count}")
                    return count
                else:
                    logger.debug(f"  âœ— è¯»å–å¤±è´¥ status={status}, out={out.strip()}, err={err.strip()}")
            else:
                logger.debug(f"  âœ— ä¸å­˜åœ¨: {sample_path}")
        
        logger.debug(f"âš  æœªæ‰¾åˆ°å…³é”®å¸§æ•°æ®: {data_dir}")
        return 0
    
    def get_keyframe_count_from_zip(self, zip_path: str) -> int:
        """ä»ZIPæ–‡ä»¶ä¸­è¯»å–å…³é”®å¸§æ•°é‡ï¼ˆä¸è§£å‹æ•´ä¸ªZIPï¼‰"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = f"/tmp/kf_extract_{Path(zip_path).stem}"
        self.ssh.exec_command(f"rm -rf '{temp_dir}'")
        self.ssh.mkdir_p(temp_dir)
        
        try:
            # å°è¯•æå– sample.json æˆ– undistorted/sample.json
            sample_paths = ["sample.json", "undistorted/sample.json"]
            
            for sample_path in sample_paths:
                # å°è¯•ä»ZIPä¸­æå–ç‰¹å®šæ–‡ä»¶
                extract_cmd = f"unzip -q -j '{zip_path}' '*/{sample_path}' -d '{temp_dir}' 2>/dev/null || true"
                self.ssh.exec_command(extract_cmd)
                
                # æ£€æŸ¥æ˜¯å¦æå–æˆåŠŸ
                extracted_file = f"{temp_dir}/sample.json"
                if self.ssh.file_exists(extracted_file):
                    # è¯»å–å…³é”®å¸§æ•°é‡
                    cmd = (
                        f"python3 -c \""
                        f"import json; "
                        f"data = json.load(open('{extracted_file}')); "
                        f"print(len(data['frames']) if isinstance(data, dict) and 'frames' in data else len(data))"
                        f"\""
                    )
                    status, out, _ = self.ssh.exec_command(cmd)
                    if status == 0 and out.strip().isdigit():
                        count = int(out.strip())
                        logger.info(f"ä»ZIPè¯»å–å…³é”®å¸§: {Path(zip_path).name} -> {count} å¸§")
                        return count
            
            logger.warning(f"æ— æ³•ä»ZIPä¸­æå–sample.json: {zip_path}")
            return 0
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            self.ssh.exec_command(f"rm -rf '{temp_dir}'")
    
    def move_to_final(self, stem: str) -> Tuple[bool, str]:
        """ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•ï¼Œå¹¶æ¸…ç†åŸå§‹ ZIP"""
        server = self.ssh.server
        src = f"{server.process_dir}/{stem}"
        dst = f"{server.final_dir}/{stem}"
        zip_path = f"{server.zip_dir}/{stem}.zip"
        
        # æ£€æŸ¥æºç›®å½•
        if not self.ssh.dir_exists(src):
            return False, "æºç›®å½•ä¸å­˜åœ¨"
        
        # å¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œç›´æ¥åˆ é™¤ï¼ˆä¸å¤‡ä»½ï¼‰
        if self.ssh.dir_exists(dst):
            self.ssh.exec_command(f"rm -rf '{dst}'")
        
        # ç§»åŠ¨
        status, _, err = self.ssh.exec_command(f"mv '{src}' '{dst}'")
        
        if status != 0:
            return False, f"ç§»åŠ¨å¤±è´¥: {err}"
        
        # æ•´ä¸ªæµç¨‹å®Œæˆåï¼Œå¤„ç†åŸå§‹ ZIPï¼ˆé¿å…ä¸­é€”å¤±è´¥å¯¼è‡´é‡å¤ä¸Šä¼ ï¼‰
        if self.config.zip_after_process == "rename":
            new_name = f"{server.zip_dir}/processed_{stem}.zip"
            self.ssh.exec_command(f"mv '{zip_path}' '{new_name}'")
        elif self.config.zip_after_process == "delete":
            self.ssh.exec_command(f"rm -f '{zip_path}'")
        
        return True, dst
